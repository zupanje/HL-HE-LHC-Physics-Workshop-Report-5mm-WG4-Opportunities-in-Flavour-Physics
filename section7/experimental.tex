\subsection{Experimental perspective (including interplay with Belle II)}
\subsubsection{Measurements of $b\to ll$ from LHCb/ATLAS/CMS}

In 2017 LHCb measured~\cite{LHCb-PAPER-2017-001} ${\cal B}(\decay{\Bs}{\mumu})=\left(3.0\pm 0.6^{+0.3}_{-0.2}\right)\times 10^{-9}$ and ${\cal B}(\decay{\Bd}{\mumu})=\left(1.5^{+1.2 +0.2}_{-1.0 -0.1}\right) \times 10^{-10}$ using data collected in $pp$ collisions corresponding to a total integrated luminosity of 4.4\invfb (Fig.~\ref{fig:btomumu}, left). Both measurements are compatible with the SM predictions but statistically limited. 

\begin{figure}[!tb]
\centering
\includegraphics[scale=0.37]{section7/figures/btomumu_BF.pdf}
\includegraphics[scale=0.4]{section7/figures/btomumu_decaytime.pdf}
\caption{(Left) A two-dimensional representation of the LHCb branching fraction measurements for \Bdmm and \Bsmm. The central values are indicated with the black plus sign. The profile likelihood contours for 1,2,3\dots $\sigma$ are shown as blue contours. The Standard Model value is shown as the red cross labelled SM. (Right) Background-subtracted \Bsmm decay-time distribution with the fit result superimposed.}
\label{fig:btomumu}
\end{figure}

While the uncertainty of ${\cal B}(\decay{\Bd}{\mumu})$  remains statistically limited on a 300\invfb dataset, the projected uncertainty of ${\cal B}(\decay{\Bs}{\mumu})$ depends on the assumptions made for the systematic uncertainties. The current systematic uncertainty is dominated by the 5.8\% relative uncertainty associated to the $b$-quark fragmentation probability ratio ($f_s/f_d$)~\cite{fsfd} followed by approximately 3\% from the branching fractions of the normalisation modes, 2\% from particle identification and 2\% from track reconstruction.
The projected relative statistical uncertainty of the current analysis on a dataset of 300\invfb is 1.8\%. 
At the end of the Upgrade II data taking period, it is reasonable to assume a systematic uncertainty on ${\cal B}(\decay{\Bs}{\mumu})$ of about 4\%, which
would imply an
uncertainty of ${\cal B}(\decay{\Bs}{\mumu})$ to be approximately $0.30\times 10^{-9}$ with 23\invfb and $0.16\times 10^{-9}$ with $300\invfb$. The increased precision will be able to cover larger part of the unconstrained parameter space of MSSM models. 
The ratio of branching fractions, ${\cal B}(\decay{\Bd}{\mumu})/{\cal B}(\decay{\Bs}{\mumu})$, is a powerful observable to test minimal flavour violation. The relative uncertainty of this ratio is expected to remain limited only by statistics and decrease from $90\%$ for the current measurement to about $34\%$ with $23\invfb$ and $10\%$ with $300\invfb$. 
All estimates use the quoted SM predictions as central values for the branching ratios and similar detector and analysis performance as in Ref.~\cite{LHCb-PAPER-2017-001}. 

The estimated experimental uncertainties at 300\invfb are close to the uncertainty of the current SM prediction from theory, which is dominated by the uncertainty of the $\Bs$ decay constant, determined from lattice QCD calculations, and the CKM matrix elements. Both are expected to improve in precision in the future. 

With a 300\invfb dataset, precise measurements of additional observables are possible, namely the effective lifetime ($\tau_{\mu\mu}^{\rm eff}$) and the time-dependent \CP\ asymmetry of \Bsmm decays. Both quantities are sensitive to possible new contributions from the scalar and pseudo-scalar sector in a way complementary to the branching ratio measurement\cite{DeBruyn:2012wk}. 

The effective lifetime is related to the mean \Bs lifetime $\tau_{B_s}$ through the relation 
\begin{equation}
\tau_{\mu\mu}^{\rm eff}=\frac{\tau_{B_s}}{1-y^2_s}\frac{1+2A^{\mu\mu}_{\Delta\Gamma}y_s+y^2_s}{1+A^{\mu\mu}_{\Delta\Gamma}y_s}\,, 
\end{equation}
where $y_s=\tau_{B_s}\Delta\Gamma_s/2$ and $\Delta\Gamma_s=\Gamma_{B^0_{sL}}-\Gamma_{B^0_{sH}}$. The parameter $A^{\mu\mu}_{\Delta\Gamma}$ is equal to 1 in the SM, where only the heavy mass eigenstate decays to \mumu, but can take any value between $-1$ and 1 in scenarios beyond the SM. LHCb has performed the first measurement of the \Bsmm effective lifetime using a dataset of 4.4\invfb, resulting in $\tau_{\mu\mu}^{\rm eff}=2.04\pm 0.44\pm 0.05 \ps$~\cite{LHCb-PAPER-2017-001} (Fig.~\ref{fig:btomumu}, right). The relative uncertainty on $\tau_{\mu\mu}^{\rm eff}$ is expected to decrease to approximately 8\%  with 23\invfb and 2\% with 300\invfb, being statistically limited. While the current experimental uncertainty is larger than $\tau_{B^0_{sH}}-\tau_{B^0_{sL}}$,
a 2\% uncertainty on $\tau_{\mu\mu}^{\rm eff}$ would allow to set stringent constraints on $A^{\mu\mu}_{\Delta\Gamma}$ and in particular would allow to break the degeneracy between any possible contribution from new scalar and pseudoscalar mediators.

Assuming a tagging power of about 3.7\%\cite{LHCb-PAPER-2014-059}, a dataset of 300\invfb allows to reconstruct a pure sample of more than 100 flavour-tagged \Bsmm decays (effective yield) and measure their time-dependent \CP asymmetry. From the relation  
\begin{equation}
\frac{\Gamma(B^0_s(t)\to\mu^+\mu^-)-\Gamma(\bar{B^0_s}\to\mu^+\mu^-)}{\Gamma(B^0_s(t)\to\mu^+\mu^-)+\Gamma(\bar{B^0_s}\to\mu^+\mu^-)}=\frac{S_{\mu\mu}\sin(\Delta M_st)}{\cosh(y_st/\tau_{B_s})+A^{\mu\mu}_{\Delta\Gamma}\sinh(y_st/\tau_{B_s})}\,, 
\end{equation}
where $t$ is the signal proper time and $\Delta M_s$ is the mass difference of the heavy and light \Bs mass eigenstates, $S_{\mu\mu}$ can be measured with an uncertainty of about 0.2. On the other hand, the signal yield expected in a 23\invfb dataset is too low to allow a meaningful constraint to be set on $S_{\mu\mu}$. A nonzero value for $S_{\mu\mu}$ would automatically indicate evidence of \CP-violating phases beyond the SM.  

Being sensitive to a wider set of effective operators ($\mathcal O_7$, $\mathcal 
O_9$ and $\mathcal O_{10}$)~\cite{Kruger:2002gf}, the \bsmumugamma decay offers 
an interesting counterpart to \bsmumu. 
The theoretical branching fraction is expected to be one order of magnitude 
larger than the \bsmumu one~\cite{Melikhov:2004mk}, owing to the removal of the helicity suppression, 
when integrated over the full $q^2$ spectrum. 
However the presence of the photon makes the direct reconstruction 
challenging at LHCb.
No limit exist today on the \bsmumugamma channel, 
while the \bdmumugamma is limited at $1\times 10^{-7}$ at 90\% CL by the 
\babar experiment~\cite{Aubert:2007up}.

Given the experimental difficulty, two complementary techniques are employed  
for the study of the \bsmumugamma decay at LHCb. The first is a full reconstruction
which is more sensitive at low and mid $q^2$, where the photon energy is higher, 
and the second, recently proposed in Ref.~\cite{Dettori:2016zff}, without photon reconstruction
but only sensitive at high $q^2$. 

The only non-negligible partially reconstructed background is the (not yet 
measured) $B_d \to \mu^{+} \mu^{-} \pi^{0} \xspace$, whose branching fraction is 
theoretically estimated to be of the same order of magnitude as the signal.
The main difficulty of the measurement is therefore the combinatorial 
background, because the uncertainty on the photon momentum enlarges the signal 
width and blurs its kinematics.
Based on current reconstruction efficiencies, the expected sensitivity at the 
end of Upgrade I (Upgrade II) data taking period is $\sim 9 \sigma$ ($\sim 22 \sigma$).
The use of $B_s \to J/\psi \eta \xspace$ and $B_d \to K\pi\gamma \xspace$ as 
normalisation channels reduces the systematic uncertainties due to the selection.

The partially reconstructed method consists of studying the \bsmumugamma decay 
as a shoulder on the left of the \bsmumu peak in the dimuon mass distribution. 
The SM contribution as background has been considered negligible so far.
Conversely large branching fractions could be easily excluded~\cite{Dettori:2016zff}
when considering this as additional component. 
The SM branching fraction for this region would be around $2 \times 10^{-10}$, 
implying a first observation would be possible with Run 3 and certainly with Run 4 data, 
while extremely tight limits could already be determined with Run 2. 

\subsubsubsection{ATLAS/CMS}

HL-LHC will offer a compelling opportunity to extend the ATLAS and CMS  $B^0_s \to \mu^+\mu^-$ and  $B^0\to \mu^+\mu^-$ studies to the expected integrated high luminosity.
\par\noindent
Flexible trigger systems and inner tracker improvements will allow both experiments to maintain efficient low pT dimuon triggers and achieve good mass resolution, which are the key ingredients for the $B_{d,s} \to 2 \mu$ analysis
\par\noindent
Fig.~\ref{fig:CMSMass} shows the CMS reconstructed $B^0_s \to \mu^+\mu^-$ and  $B^0\to \mu^+\mu^-$ invariant in the barrel (left) and forward region. 
Fig.~\ref{fig:ATLASMAss} shows the $B^0_s \to \mu^+\mu^-$ reconstructed invariant mass for $|\eta| < 2.5$

The present ATLAS projections are extrapolated from the ATLAS Run I analysis \cite{Aaboud:2016ire}. Assumptions include the training of a multivariate classifier capable of similar background rejection and signal purities and an analysis selection with comparable pile-up immunity as Run 1.
The study takes into account the scaling of B production cross-section and integrated luminosity relative to Run 1, and explores different triggering scenarios corresponding to different dimuon transverse momentum thresholds:
($p_T^{\mu_1}$,$p_T^{\mu_2}$): $(6 \,\text{GeV},6 \,\text{GeV})$, $(6 \, \text{GeV},10 \,\text{GeV})$ and $(10 \,\text{GeV},10 \,\text{GeV})$.

Depending on these dimuon thresholds, three working points are obtained from detector simulations. These are expressed in terms of signal and background statistics relative to Run 1: x15 (conservative), x60 (intermediate) and x75 (high-yield).
An unbinned maximum-likelihood fit is applied to datasets generated in the assumptions discussed above, in order to produce 68.3\%, 95.5\% and 99.7\% likelihood contours.
For each level, contours are calculated for statistical-only and statistical+systematic uncertainties. The Run 1 analysis parametrizes two classes of systematic uncertainties: the
ones coming from external inputs (e.g. the $f_s/f_d$ ratio and
the $B^+\to J/\psi [\to\mu\mu]K^\pm$ branching ratio) and those depending on internal analysis effects (invariant mass fit shapes, efficiencies, etc.).
The latter category is parameterized as a function of the signal yields where dependencies are found to be significant.\\
This study extrapolates the same systematic uncertainties including the same signal yield parameterization found in the Run 1 studies. As for the external sources of systematic uncertainties, it is plausible to expect that these will be reduced with other measurements and could optimistically scale for the most part like
statistical uncertainties. This study however conservatively assumes their values to be those used in the Run 1 analysis.

Figures~\ref{fig:HLLHCextrapolation_x15}, \ref{fig:HLLHCextrapolation_x60} and \ref{fig:HLLHCextrapolation_x75} summarise the contours derived in these assumptions,
in the $BR\left[B^0 \to \mu\mu\right]$-$BR\left[B_{s}^0 \to \mu\mu\right]$ plane. Table~\ref{BMuMUTable} provides the estimated statistical and statistical+systematic uncertainties on the two branching ratios expected for the extrapolations discussed.

\begin{table}
  \centering
  \caption{Uncertainty on $\cal{B}$$(B^0_s \to \mu^+ \mu^-)$ and $\cal{B}$$(B^0 \to \mu^+ \mu^-)$ as reported
    by the fitting procedure applied to  the toy simulations. The results are centered on the SM theoretical prediction~\cite{Bobeth}.
    For each extrapolation performed, statistical and statistical+systematic uncertainties are reported in units of $10^{-10}$.
    The table reports a sufficient number of significant digits to highlight the difference between statistical+systematics and
    systematics-only uncertainties.
  }
  \label{BMuMuTable}
  \renewcommand{\arraystretch}{1.3}
  \begin{tabular}{ l c c c c }
    \hline
    & \multicolumn{2}{c}{$\cal{B}$$(B^0_s \to \mu^+ \mu^-)$ } & \multicolumn{2}{c}{$\cal{B}$$(B^0 \to \mu^+ \mu^-)$} \\
    & stat $[10^{-10}]$ & stat + syst $[10^{-10}]$ & stat $[10^{-10}]$ & stat + syst $[10^{-10}]$ \\
    \hline
    Run 2 & 7.0 & 8.3 & 1.42 & 1.43\\
    HL-LHC: Conservative  & 3.2 & 5.5 & 0.53 & 0.54\\
    HL-LHC: Intermediate  & 1.9 & 4.7 & 0.30 & 0.31\\
    HL-LHC: High-yield  & 1.8 & 4.6 & 0.27 & 0.28\\
    \hline
  \end{tabular}
\end{table}


\begin{figure}[ht]
  \centering  
  \includegraphics[width=1\textwidth]{\main/section7/figures/plot_preliminary_x15.pdf}
  \caption{Comparison of 68.3\% (solid), 95.5\% (dashed) and 99.7\% (dotted) confidence level profiled likelihood ratio contours for the
    working point at $\times 15$ Run 1 statistics. This corresponds to the 'conservative' HL-LHC extrapolation, based on yield
    projections for the $(10 \text{GeV},10 \text{GeV})$ dimuon trigger.
    Red contours do not include the systematic uncertainties, which are then included
    in the blue ellipsoids. The black point shows the SM theoretical prediction and its uncertainty \cite{Bobeth}.}
  \label{fig:HLLHCextrapolation_x15}
\end{figure}


\begin{figure}[ht]
  \centering
\includegraphics[width=1\textwidth]{\main/section7/figures/plot_preliminary_x60.pdf}
  \caption{Comparison of 68.3\% (solid), 95.5\% (dashed) and 99.7\% (dotted) confidence level profiled likelihood ratio contours for the
    working point at $\times 60$ Run 1 statistics. This corresponds to the 'intermediate' HL-LHC extrapolation, based on yield
    projections for the $(6 \text{GeV},10 \text{GeV})$ dimuon trigger.
    Red contours do not include the systematic uncertainties, which are then included
    in the blue ellipsoids. The black point shows the SM theoretical prediction and its uncertainty \cite{Bobeth}.}
  \label{fig:HLLHCextrapolation_x60}
\end{figure}

The current CMS projection, compared to the previous Run-I analysis \cite{CMSRun1},  includes a more advanced UML fit and an improved muon identification algorithm. 
The impact of a PU scenario of 200 interactions was found not to have strong impact on the isolation variable distributions. The signal-to-background ratio (S/B), which depends on momentum resolution, is best in the barrel region and degrades  if one or both muons are detected in the forward region. Therefore, the analysis is performed in two different regions defined by the pseudorapidity of the most forward muon   $|\eta_f|$, defined  as $|\eta_f|  < 0.7$ and  0.7 < $|\eta_f|  <1.4$.
Fig.~\ref{fig:CMSMass}  shows the invariant mass distributions with the fit projection overlayed, corresponding to an
integrated luminosity of 3000 fb$^{-1}$ for the two $\eta_f|$ regions.

 \begin{figure}[htbp]
   \begin{center}
    \includegraphics[width=0.5\textwidth]{\main/section7/figures/CMS_mass_barrel.pdf}
     \includegraphics[width=0.5\textwidth]{\main/section7/figures/CMS_mass_forward.pdf}
       \caption{Invariant mass distributions with the fit projection overlayed, corresponding to an
integrated luminosity of 3000 fb$^{-1}$. 
    The left plot shows the central barrel region, $\eta| $< 0.7 and the right plot is for to 0.7< $\eta|$ < 1.4.}
     \label{fig:CMSMass}\end{center}\end{figure}\setlength{\extrarowheight}{4pt}     


An unbinned maximum likelihood fit to the dimuon invariant mass distribution is performed to determine the $\mathrm{B^0_s} \to \mu ^+ \mu^-$ effective 
lifetime. Based on the fitting results, a projection along the proper decay time distribution for the $B^0_s$ signal events is built with the 
sPlot technique [ref for sPlot and FTR-18-013]. The model used in the lifetime fit is based on an exponential function, convoluted with a Gaussian
function which describes the expected decay time resolution.

Fig~\ref{fig:lifetime} shows the $\mathrm{B^0_s}$ decay time distribution with the fit projection superimposed.
The effective lifetime from the fit is 1.61 $\pm$ 0.05 ps.

   \begin{figure}[htbp]
   \begin{center}
    \includegraphics
    [width=0.5\textwidth]{\main/section7/figures/CMS_tau_splot_toy_bs.pdf}
       \caption{The binned maximum likelihood fit to the decay time distribution for the Phase-II scenario}
     \label{fig:lifetime}\end{center}\end{figure}\setlength{\extrarowheight}{4pt}     

The major sources of systematic uncertainties, listed in Table~\ref{tab:b2musys}, are from external physics parameters 
(e.g. fu/ fs ratio and SM branching fractions of  $\mathrm{B}\to  \mu^+ \mu^-$  and B$^+ \to   \mathrm{J}/\psi K^+$ ) and those depending on internal 
analysis effects (e.g. individual signal and background yields, efficiencies, etc.) 

The uncertainty on the muon identification(ID) efficiency ratio is determined by the difference of data and MC efficiency ratio 
from $\mathrm{B^+ \to  J}/\psi K^+$ and $\mathrm{B^0_s \to J}/\psi \phi$ is assumed to diminish to 1 \% 
for the Phase-II case.  In this study, it is expected that the dimuon trigger for the signal and normalization channels will 
remain the same 
The major systematics shown in Table~\ref{tab:b2msys} are implemented in the PDFs as nuisance parameters.The external input to UML, the value of 
$f_u/f_s$ relative uncertainty is currently 5.8\%: This uncertainty is assumed to be 3.5 \%, which is dominated by systematic uncertainties 
from form-factor ratios and branching fraction measurements.

The systematic uncertainty on the normalization yield enters the branching fraction directly. We determine this uncertainty from the yield 
difference between the results of the unconstrained $\mathrm{B+}$ and fit the J/$\psi$ mass-constrained invariant mass distribution.
The Belle II collaboration is expected to be able to improve this measurement to 1,4 \%.
The uncertainty due to the peaking and semileptonic backgrounds is currently dominated by the uncertainty on the hadron misidentification probability.
To determine the systematic uncertainty on the muon misidentification probability for pion, kaons and protons, we calculate the bin-averaged 
misidentification probability for data and MC simulation. From these values and their uncertainties we calculate the error-weighted average and
its uncertainty. The relative uncertainty of this average is used as systematic uncertainty.
We assume the uncertainty on hadron misID to be 10\%.
As a result of this, the relative uncertainties on the yield of peaking and semileptonic background are 20 \% and 15 \% respectively, during Run 2.
As a reasonable assumption, these two uncertainties are expected to reduce by a factor of 2 and to be 10 \% and 7.5 \% respectively for the Phase II
scenario.

The selection efficiency depends on the $\mathrm{B^0_s}$ effective lifetime.and its uncertainty assumed to be 2\% during Phase II era.
The systematic uncertainty for the determination of the $\mathrm{B^0_s} \to \mu^+\mu^-$ effective lifetime will be limited by the knowledge 
of the trigger efficiency as a funztion of the $\mathrm{B^0_s}$ decay time.
We expect that this uncertainty can be well measured with the $\mathrm{B^+} \to J/\psi K^+$ decay using simila triggers ( except for the dimuon mass
range).
The trigger efficiency is estimated by the difference between the dimuon triggers for signal and for j/$\psi$ which is assumed to dimish to 1.5 \% 
Other sources of systematics (acceptance, selection, etc) have been studied and the related uncertainties halved: the sensitoivity for 
the significance of the $\mathrm{B^0}$ observation ans its branching fraction is not significantly affected whereas there is a 1 \% improvement 
on the sensitivity for the $\mathrm{B^0_s}$ branching fraction. 
The quadratic sum of these uncertainties is 3\% 


\begin{table}
\centering
\caption{Systematic uncertainties for Phase II  scenario.}
\label{tab:b2musys}
\begin{tabular}{cc}\hline
Source & Uncertainty \\ \hline Muon ID efficiency ratio & 1\% \\ 
$\mathrm{B^+}$ normalization yield & 1,4\% \\
Peaking background yield & 10\% \\ 
Semileptonic background yield & 7,5\% \\
fs/fu ratio & 3.5\% \\Effective lifetime & 2\% \\
Trigger efficiency & 1,5\%\\\hline
\end{tabular}\end{table}

The sensitivities of the measurement for the $\mathrm{B^0_s}$ effective lifetime and branching fractions of the rare decays 
$\mathrm{B^0_s}$ and $\mathrm{B^0}$ to dimuons are reported in Table~\ref{tab:b2musensitivity} 
The total relative uncertainties on the branching fractions of the $\mathrm{B^0_s }\to \mu^+\mu^-$ and $\mathrm{B^0} \to \mu^+\mu^-$ include 
both systematic and statistical uncertainties, while the unceratinty on the $\mathrm{B^0_s}$ effective lifetime is statistical only.


\begin{table}[!htb]
\begin{center}
\caption{Estimated analysis sensitivity for different integrated luminosities. 
Columns in the table, from left to right: the total integrated luminosity, the number of reconstructed $\mathrm{B^0_s}$ and $\mathrm{B^0}$  
mesons, the total uncertainties on the bsmm and bdmm branching fractions, the range of the significance of $\mathrm{B^0}$ 
observation(the range indicates the $\pm 1 \sigma$ of the distribution of significance) and the statistical uncertainty on the 
bsm effective lifetime. All results are based on the Phase II  detector configuration except for the first row.} 
\label{tab:b2musensitivity}
\begin{tabular}{l|l|l|l|l|l|l} $\mathcal{L}$ (fb$^{-1}$) & $N(B_s)$ & $N(B^0)$ & $\delta\mathcal{B}(B_s\to\mu\mu)$ & 
$\delta\mathcal{B}(B^0\to\mu\mu)$ & $\sigma(B^0\to\mu\mu)$ & $\delta[\tau(B_s)]$\\ \hline
300 & 205 & 21 & 12\% & 46\% & $1.2-3.3\sigma$ &
 0.15 \\ 3000 & 2048 & 215 & 7\% & 16\% & $6.0-8.3\sigma$ & 0.05 \\
\end{tabular}\end{center}\end{table}


\subsubsection{Measurements of $b\to sll$ from LHCb/ATLAS/CMS}

In order to estimate our sensitivity to BSM effects in $b\to sll$ decays, a number of benchmark NP scenarios are considered (see Table~\ref{tab:penguins:NPscenarios}). 
Scenarios~I and II are inspired by the current discrepancies. The first scenario is the one that best explains the present rare semileptonic decay data. The second scenario best explains the rare semileptonic measurements if a purely left-handed coupling to
quarks and leptons is required for NP. This requirement is theoretically well motivated and arises in models designed to simultaneously explain the discrepancies seen in both tree-level semitauonic and loop-level semileptonic decays. The third and fourth scenarios assume that the current discrepancies are not confirmed but there is instead a small contribution from right-handed currents that would not be visible with the current level of experimental precision. These scenarios will serve to illustrate the power of the large \upgradetwo data set to distinguish between different NP models.
This power relies critically on the ability to exploit multiple related decay channels. 

\begin{table}[!tb]
   \centering
\caption{
    Benchmark NP scenarios. The first scenario is inspired by the present discrepancies in the
    rare decays, including the angular distributions of the decay \decay{\Bz}{\Kstarz\mumu} and the measurements of the branching fraction ratios $R_K$ and $R_{K^*}$. 
    The second
    scenario is inspired by the possibility of explaining the
    rare decays discrepancies and those measured in the observables
    $R(D^{(*)})$. The third and fourth scenarios assume a small 
    right-handed chirality coupling. The Wilson coefficients ($C_i$) are discussed in Sec.~\ref{sec:penguins:framework}} 
            \label{tab:penguins:NPscenarios}
   \begin{tabular}{crrrr}
       \hline
            scenario & $C_9^{\rm NP}$ & $C_{10}^{\rm NP}$ & $C_{9}^{\prime}$ & $C_{10}^{\prime}$ \\
       \hline
       I & $-1.4$ & 0 & 0 & 0 \\
       II & $-0.7$ & 0.7 & 0 & 0\\
       III & 0 & 0& 0.3 & 0.3\\
       IV & 0 & 0& 0.3 & $-0.3$\\
       \hline
   \end{tabular}
\end{table}

The branching fractions of a number of exclusive $\bquark\to\squark \ellell$ processes have been studied using the LHCb Run~1 data set. The experimental measurements are systematically lower than their corresponding SM predictions. The largest discrepancy appears for $\BF(\decay{\Bs}{\phi\mumu})$ which, in the  $1<q^2<6\gevgevcccc$ region, is more than $3\,\sigma$ from the SM predictions~\cite{LHCb-PAPER-2015-023}.
For both the \upgradeone and \upgradetwo datasets,the precision of the measurement of the branching fractions will be limited by the knowledge of the \decay{\B}{\jpsi X} decay modes that are used to normalise the observed signals. 
The knowledge of these branching fractions will be improved by the \belletwo collaboration but will inevitably limit the precision of the absolute branching fractions of rare $\bquark\to\squark \ellell$ processes. 
The comparison between the predicted and measured branching fractions will in any case be limited by the theoretical knowledge of the form factors, even if in the future these are determined parameterically using the data.
A better comparison between theory and experiment can be achieved by studying isospin and \CP asymmetries, which with the \upgradetwo data set will be experimentally probed with percent level precision. The \upgradetwo data set will also enable new decay modes to be studied, for example higher spin-\Kstar states and modes with larger numbers of decay products.  

It is also possible to reduce theoretical and experimental uncertainties by comparing regions of angular phase-space of $\bquark\to\squark \ellell$ decays. 
The angular distribution of \decay{\B}{V \ellell} decays, where $V$ is a vector meson, can be expressed in terms of eight \qsq-dependent angular coefficients that depend on the Wilson coefficients and the form-factors. 
Measurements of angular observables in \decay{\Bz}{\Kstarz\mumu} decays show a
discrepancy with respect to SM predictions~\cite{LHCb-PAPER-2013-037,LHCb-PAPER-2015-051,LHCb-PAPER-2014-006,LHCb-PAPER-2013-019,Aubert:2006vb,Lees:2015ymt,Wei:2009zv,Aaltonen:2011ja,Chatrchyan:2013cda,Khachatryan:2015isa,Aaboud:2018krd,Sirunyan:2017dhj,Beneke:2004dp,Egede:2015kha,Kruger:2005ep,Lyon:2014hpa,Hurth:2013ssa,Beaujean:2013soa,Altmannshofer:2013foa,Descotes-Genon:2013wba}. 
This discrepancy is largest in the so-called form-factor independent observable $P'_{5}$~\cite{LHCb-PAPER-2015-051}. 
The decay \decay{\Bs}{\phi\mumu} can also be described by the same angular formalism as the \decay{\Bz}{\Kstarz\mumu} decay.
However, in this case the \Bs and the \Bsb mesons decay to a common final state and it is not possible to determine the full set of observables   without tagging the initial flavour of the \Bs. 
This is discussed further in Sec.~\ref{sec:penguin:timedependent}. 

With the large data set that will be collected with \upgradetwo,  
corresponding to around 440\,000 fully reconstructed \decay{\Bz}{\Kstarz\mumu} decays, it will
be possible to make a precise determination of the angular observables in narrow
bins of \qsq or using a \qsq-unbinned approach~\cite{Hurth:2017sqw}. 
The expected precision of an unbinned determination of $P_5^{\prime}$ in the SM and in Scenarios~I and II is illustrated in Fig.~\ref{fig:penguin:P5primeUnbinned}. 
\upgradetwo will enable these scenarios to be clearly separated from the SM and from each other.
By combining information from all of the angular observables in the decay, it will also be possible to distinguish models with much smaller NP contributions. 
Figure~\ref{fig:penguin:WCKstmm} shows the expected $3\,\sigma$ sensitivity for the Wilson
coefficients for $C_{9,10}^{\prime}$ for the SM, Scenario~III and Scenario~IV.  
These scenarios are also clearly distinguishable with the precision that will be available with the \upgradetwo data set.

\begin{figure}[!tb]
\centering
\includegraphics[width=0.45\linewidth]{section7/figures/P5p_Run3.pdf}
\includegraphics[width=0.45\linewidth]{section7/figures/P5p_HL.pdf}
\caption{Experimental sensitivity to the $P_5^{\prime}$ angular observable in the SM,
  Scenarios~I and II for (left) the Run~3 and (right) the \upgradetwo data sets. 
  The sensitivity is computed assuming that the charm-loop contribution is determined from the data.
}
\label{fig:penguin:P5primeUnbinned}
\end{figure}

\begin{figure}[!tb]
\centering
\includegraphics[width=0.4\linewidth]{section7/figures/ellipses_Cp_Run3.pdf}
\includegraphics[width=0.4\linewidth]{section7/figures/ellipses_Cp_HL.pdf}
\caption{Expected sensitivity for the Wilson coefficients $C_9^{\prime}$ and
  $C_{10}^{\prime}$ from the analysis of the decay \decay{\Bz}{\Kstarz\mumu}. 
  The ellipses correspond to 3\,$\sigma$ contours for
  the SM, Scenario~III and Scenario~IV for (left) the Run~3 and (right) the \upgradetwo data sets. 
  }
  \label{fig:penguin:WCKstmm}
\end{figure}

The major challenge for \decay{\B}{V \ellell} decays is to disentangle NP effects from
SM contributions. 
With a large data set it will be possible to probe the SM contributions, under the premise that a genuine NP contribution is expected to have no $q^2$ dependence, while \eg a 
charm loop contribution is expected to grow approaching the pole of
the charmonia resonances.  
A measurement using Breit-Wigner functions to parametrise the
resonances, and their interference with the
short-distance contributions to the decay, is proposed in Ref.~\cite{Blake:2017fyh}. 
A similar technique has already been applied to the Run~1 data for the \decay{\Bp}{\Kp\mumu} decay~\cite{LHCb-PAPER-2016-045}. 
An alternative approach using additional phenomenological inputs has also been proposed~\cite{Bobeth:2017vxj}.
A precise knowledge of the charm loop contribution and a parametric determination of the form factors,
 will come from a combination of phenomenological and experimental
methods and will allow $C_9$ and
$C_{10}$ to be determined with great precision in $\bquark\to\squark\mumu$ transitions.

%Sandra: including CMS P5'
\subsubsubsection{CMS P5' sensitivity}
The expected $\mathrm{B^0}$ signal yield per each $q^2$ bin is measured on the Phase II MC sample.
An extended unbinned maximum likelihood fit is performed to the $K^+\pi^-\mu^+\mu^-$ invariant mass in each bin, parametrizing the signal with 
the sum of two Gaussian distributions and the background with an exponential distribution. 
 The expected yield of fully reconstructed $\mathrm{B^0}\to \mathrm{K^{*0}} \mu^+\mu^-$ signal events, excluding the $q^2$ range 
 overlapping with the resonant decays, is around 700~k.
 The projected statistical uncertainty on the $\mathrm{P'_5}$  parameter measurement is obtained scaling the statistical uncertainty measured in Run I 
 according to the square root of the ratio between the corresponding signal yields.
 The evolution of the systematic uncertainties is estimated by rescaling 
 the values evaluated in the Run I analysis 
 \cite{Sirunyan:2017dhj}.
Uncertainties concerning the simulation mismodeling, the fit bias introduced by the fitting procedure, the efficiency determination,
 the $K\pi$ mistagging rate, the choice of the signal mass pdf, the effect of the contamination from feed-through events from the resonant decays,
 and the angular resolution are assumed to be reduced by a factor of 2 in the Phase II scenario; 
 the uncertainty on the description of the background mass distribution and the one associated with the propagation of the uncertainty 
 on $F_L$, $F_S$ and $A_S$ depend on the available amount of data. These uncertainties are therefore scaled by the ratio of the square root 
 of the number of events.The uncertainty due to the finite size of the simulation is considered to be zero in the Phase II scenario.
\par\noindent
The projections for the measurement of $\mathrm{P'_5}$ versus $q^2$ are shown in Fig.~\ref{fig:CMSP5presults}, together with the measurements from the Run I analysis.
 \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=0.6\textwidth]{section7/figures/R1_and_errorP2_rebinningSystButStatOnly.pdf}
 \caption{Projection of the CMS sensitivity on the $\mathrm{P'_5}$ parameter versus $q^2$ in the Phase II scenario at 3000 fb$^{-1}$, shown with the black shaded region. The red shaded region correspond to the projected statistical uncertainty. The measurement of $\mathrm{P'_5}$ from the CMS Run I analysis is reported in pale-blue: the statistical uncertainties are shown by the  vertical bars, while the outer vertical bars represent the total uncertainties. 
 The vertical shaded regions correspond to the J/$\psi$ and $\psi'$ resonances.The lower pads represent the total (black) and statistical (red) 
uncertainties for an optimized finer $q^2$ binning.} 
 \label{fig:CMSP5presults}
 \end{center}
 \end{figure}
The projections for the Statistical-only scenario are also included.
\par\noindent    
The increased amount of collected data foreseen for the Phase II integrated luminosity offers the opportunity to perform the angular analysis in
 narrower $q^2$ bins, in order to measure the $\mathrm{P'_5}$  shape as a function of $q^2$ with finer granularity. The $q^2$ region below the J/$\psi$ 
  mass(squared), which is more sensitive to possible new physics effects, is considered. Each Run I $q^2$ bin is split into smaller 
 and equal-size bins trying to achieve a statistical uncertainty of the order of the total systematic uncertainty in the same bin with the
 additional constraint of having a bin width at least 5 times larger than the dimuon mass resolution $\sigma_r$.
 If both conditions cannot be satisfied, then only the looser requirement on the 5 $\sigma_r$ bin width is imposed.
 The dimuon mass resolution is measured on the MC simulation as a function of $q^2$.Each systematic uncertainty in the Run I analysis bin is 
 rescaled to the finer bins according to its classification and correlation between $q^2$ bins.
\par\noindent
The corresponding total and statistical only uncertainties 
 on $\mathrm{P'_5}$  are shown in the two lower pads of Fig.~\ref{fig:CMSP5presults}.

\subsubsection{Measurements of $b\to dll$}

The \upgradetwo data set will provide a unique opportunity to make precise measurements of $\bquark\to\dquark \ellell$ processes. 
Using the Run~1 and 2 data sets, LHCb data have been used to observe the decays \decay{\Bp}{\pip\mumu}~\cite{LHCb-PAPER-2012-020,LHCb-PAPER-2015-035} and \decay{\Lb}{p\pim\mumu}~\cite{LHCb-PAPER-2016-049} and find evidence for the decays \decay{\Bz}{\pip\pim\mumu} (in a $\pip\pim$ mass region that  is expected to be dominated by \decay{\Bz}{\rhoz\mumu}) and \decay{\Bs}{\Kstarzb\mumu}~\cite{LHCb-PAPER-2018-004} with branching fractions at the $\mathcal{O}(10^{-8})$ level.
The existing data samples comprise $\mathcal{O}(10)$ decays in these decay modes. 
The upgrade will provide samples of thousands, or tens of thousands of such decays.
The ability to measure the properties of these processes depends heavily on the PID performance of the LHCb subdetectors. 
In the case of the \decay{\Bs}{\Kstarzb\mumu} decay, excellent mass resolution is also critical to separate \Bs and \Bz decays. 

The ratio of branching fractions between the CKM-suppressed $b \to d\ellell$ transitions and their CKM-favoured  $\bquark \to \squark \ellell$ counterparts, together with theoretical input on the ratio of the relevant form factors, enables the ratio of CKM elements  $|V_{td}|/|V_{ts}|$ to be determined. The precision on $|V_{td}|/|V_{ts}|$ from such decays is presently dominated by the statistical uncertainty on the experimental measurements of \decay{\Bp}{\pip\mumu}, and is much less precise than the determination from mixing measurements. The theoretical uncertainty is at the level of 4\% and is expected to improve with further progress on the form-factors from lattice QCD. Around 17\,000 \decay{\Bp}{\pip\mumu} decays are expected in the full 300\invfb dataset, allowing an experimental precision better than 2\%.

The current set of measurements of $\bquark\to\squark \ellell$ processes have demonstrated the importance of angular measurements in the precision determination of Wilson coefficients. With the \upgradetwo dataset, where a sample of 4300  \decay{\Bs}{\Kstarzb\mumu} decays is expected,  it will be possible to make a full angular analysis of a $\bquark\to\dquark \ellell$ transition. The \decay{\Bs}{\Kstarzb\mumu} decay is both self-tagging and has a final state involving only charged particles. The \upgradetwo data set will allow the angular observables in this decay to be measured with better precision than the existing measurements of the \decay{\Bz}{\Kstarz\mumu} angular distribution. 

The \upgradetwo dataset will also give substantial numbers of \decay{\B^{0,+}}{\rho^{0,+}\mumu}  and \decay{\Lb}{N\mumu} decays. Although the  \decay{\Bz}{\rhoz\mumu} decay does not give the flavour of the initial \B meson, untagged measurements will give sensitivity to a subset of the interesting angular observables. 
Analysis of the \decay{\Lb}{N^{*}\mumu} decay will require statistical separation of  overlapping $p\pim$ resonances with different $J^P$ by performing an amplitude analysis of the final-state particles. 

The combination of information from $\BF(\decay{\Bz}{\mumu})$, the differential branching fraction of the \decay{\Bp}{\pip\mumu} decay, and angular measurements, notably of \decay{\Bs}{\Kstarzb\mumu}, will indicate whether NP effects are present in $\bquark\to\dquark$ transitions at the level of 20\% of the SM amplitude with more than $5\sigma$ significance. 

\subsubsection{LFU tests in $b\to (s,d)ll$}

The Run~1 \lhcb data have been used to perform the most precise measurements of $R_{K}$ and $R_{\Kstar}$ to-date~\cite{LHCb-PAPER-2017-013,LHCb-PAPER-2014-024} (see Fig.~\ref{fig:penguin:RXscenarios}).
These measurements are compatible with the SM at the level of 2.1--2.6 standard deviations. Assuming the current detector performance, approximately 46\,000 \decay{\Bp}{\Kp\epem} and 20\,000 \decay{\Bz}{\Kstarz\epem} candidates are expected in the range $1.1 < \qsq < 6.0\gevgevcccc$ in the \upgradetwo data set.
The ultimate precision on $R_{K}$ and $R_{\Kstar}$ will be better than 1\%.
The importance of the \upgradetwo data set in distinguishing between different NP scenarios is highlighted in Fig.~\ref{fig:penguin:RXscenarios}. 
With this data set all four NP scenarios could be distinguished at more than 5\,$\sigma$ significance.

The \upgradetwo data set will also enable the measurement of other $R_{X}$ ratios \eg $R_{\phi}, R_{p\kaon}$ and the ratios in CKM suppressed decays. 
For example, with 300\invfb, it will be possible to determine $R_{\pi}=\BR(\decay{\Bp}{\pip\mumu})/\BR(\decay{\Bp}{\pip\epem})$ with a few percent statistical precision.
A summary of the expected performance for a number of different $R_X$ ratios is indicated in Table~\ref{tab:penguin:LU_extrapolations}.

\begin{figure}[!t] 
\centering
\includegraphics[width=0.75\textwidth]{section7/figures/RX_scenario.pdf}
\caption{
Projected sensitivity for the $R_{K}$, $R_{K^*}$ and $R_{\phi}$ measurements in different NP scenarios with the Upgrade~II data set. 
The existing Run~1 measurements of $R_{K}$ and $R_{K^*}$ are shown for comparison. 
}
\label{fig:penguin:RXscenarios}
\end{figure}

\begin{table}[!tb]
\caption{
Estimated yields of $\bquark\to\squark\ep\en$ and $\bquark\to\dquark\ep\en$ processes and the statistical uncertainty on $R_{X}$ in the range $1.1<\qsq<6.0\gevgevcccc$ extrapolated from the Run~1 data. 
A linear dependence of the \bbbar production cross section on the $pp$ centre-of-mass energy and unchanged Run~1 detector performance are assumed. 
Where modes have yet to be observed, a scaled estimate from the corresponding muon mode is used.
}
\label{tab:penguin:LU_extrapolations}
\centering
\begin{tabular}{lrrrrr}
\hline
Yield  & Run~1 result & 9\invfb & 23\invfb & 50\invfb & 300\invfb \\
\hline
 \decay{\Bu}{\Kp\epem} 		& $254 \pm 29$\cite{LHCb-PAPER-2014-024} & 1\,120 & 3\,300 & 7\,500 & 46\,000 \\
 \decay{\Bd}{\Kstarz\epem}	& $111 \pm 14$\cite{LHCb-PAPER-2017-013} & 490 & 1\,400 & 3\,300 & 20\,000 \\
 \decay{\Bs}{\phi\epem}		& -- & 80 & 230 & 530 & 3\,300 \\
 \decay{\Lb}{\proton\kaon\epem} & -- & 120 & 360 & 820 & 5\,000 \\
\decay{\Bp}{\pip\epem}		& -- & 20 & 70 & 150 & 900 \\ 
\hline
$R_X$ precision &  Run~1 result & 9\invfb & 23\invfb & 50\invfb & 300\invfb \\
\hline
$R_{\kaon}$					& $0.745 \pm 0.090\pm 0.036$\cite{LHCb-PAPER-2014-024} & 0.043 & 0.025 & 0.017 & 0.007 \\
$R_{\Kstarz}$					& $0.69 \pm 0.11\pm 0.05$\cite{LHCb-PAPER-2017-013} & 0.052 & 0.031 & 0.020 & 0.008 \\
$R_{\phi}$					& -- & 0.130 & 0.076 & 0.050 & 0.020 \\
$R_{\proton\kaon}$  & -- & 0.105 & 0.061 & 0.041 & 0.016 \\
$R_{\pi}$						& -- & 0.302 & 0.176 & 0.117 & 0.047 \\ 
\hline
\end{tabular}
\end{table}

In addition to improvements in the $R_{X}$ measurements, the enlarged \upgradetwo data set will give access to new observables. For example, the data will allow precise comparisons of the angular distribution of dielectron and dimuon final-states. 
Differences between angular observables in \decay{\B}{X\mumu} and \decay{\B}{X\ep\en} decays are theoretically pristine~\cite{Capdevila:2016ivx}
and are sensitive to different combinations of Wilson coefficients compared to the $R_X$ measurements. 
Figure~\ref{fig:penguin:DeltaC} shows that an upgraded \lhcb detector will enable such decays to be used to discriminate between different NP models, for example separating between Scenarios~I and II. 
Excellent NP sensitivity can be achieved irrespective of the assumptions made about the hadronic contributions to the decays.

\begin{figure}[t!]
\centering
\includegraphics[width=0.49\textwidth]{section7/figures/ellipses_DeltaC_Run3.pdf}
\includegraphics[width=0.49\textwidth]{section7/figures/ellipses_DeltaC_HL.pdf}
\caption{
Constraints on the difference in the $C_9$ and $C_{10}$ Wilson coefficients from electron and muon modes with (left) Run~3 and (right) \upgradetwo data sets. The $3\sigma$ regions are shown for the SM (blue), for a vector-axial-vector new physics contribution (red) and for a purely vector new physics contribution (green).}
\label{fig:penguin:DeltaC}
\end{figure}

In the existing \lhcb detector, electron modes have an approximately factor five lower efficiency than the corresponding muon modes, owing to the tendency for the electrons to lose a significant fraction of their energy through bremsstrahlung in the detector. 
This loss impacts on the ability to reconstruct, trigger and select the electron modes.
The precision with which observables can be extracted therefore depends primarily on the electron modes and not the muon modes.
In order for $R_{X}$ measurements to benefit from the large \upgradetwo data samples, it will be necessary to reduce systematic uncertainties to the percent level.
These uncertainties can be controlled by taking a double ratio between $R_{X}$ and the decays \decay{\B}{\jpsi X}, where the \jpsi decays to \mumu and $\ep\en$.
This approach is expected to work well, even with very large data sets.  

Other sources of systematic uncertainty can be mitigated through design choices for the upgraded detector.
The recovery of bremsstrahlung photons is inhibited by the ability to find the relevant photons in the ECAL (over significant backgrounds) and by the energy resolution.
A reduced amount of material before the magnet would reduce the amount of bremsstrahlung and hence would increase the electron reconstruction efficiency and improve the electron momentum resolution. 
Higher transverse granularity would aid signal selection and help reduce the backgrounds. 
With a large number of primary $pp$ collisions, the combinatorial background will increase and will need to be controlled with the use of timing information.
However, the Run~1 data set indicates that it may be possible to tolerate a significant (\ie\ larger than a factor two) increase in combinatorial backgrounds without destroying the signal selection ability.

\subsubsection{Time dependent angular analyses in $b\to (s,d)ll$}

Time dependent analyses of rare decays into \CP-eigenstates can deliver orthogonal experimental information to time-integrated observables. 
So far, no time-dependent measurement of the $\decay{\Bs}{\phi\mumu}$ decay has been performed due to the limited signal yield of $432\pm 24$ in the Run~1 data sample~\cite{LHCb-PAPER-2015-023}.
However, the larger data samples available in \upgradetwo will enable time-dependent studies. 
The framework describing $\Bbar$ and $\B\to V\ellell$ transitions to a common final-state is discussed in  Ref.~\cite{Descotes-Genon:2015hea}, 
where several observables are discussed that can be accessed with and without flavour tagging.  
Two observables called $s_8$ and $s_9$, which are only accessible through a time-dependent flavour-tagged analysis, are of particular interest. 
These observables  are proportional to the mixing term $\sin\left(\Delta m_s t\right)$ and provide information that is not available through flavour specific decays.
Assuming a time resolution of around $45\fs$ and an effective tagging power of $5\%$ 
results in an effective signal yield of  $2000$ decays for the \upgradetwo data set. 

As a first step towards a full time-dependent analysis, the effective lifetime of the decay $\decay{\Bs}{\phi\mumu}$ can be studied. 
The untagged time-dependent decay rate is given by
\begin{align}
  \frac{\deriv\Gamma}{\deriv t} &\propto  e^{-\Gamma_s}\left[\cosh\left(\frac{\Delta\Gamma_st}{2}\right)+A^{\Delta\Gamma}\sinh\left(\frac{\Delta\Gamma_st}{2}\right)\right].
\end{align}
The observable $A^{\Delta\Gamma}$ can be related to the angular observables $F_{\rm L}$ and $S_3$ via $A^{\Delta\Gamma}=2S_3-F_{\rm L}$. 
Due to the significant lifetime difference $\Delta\Gamma_s$ in the \Bs\ system, even an untagged analysis can probe right-handed currents. 
For the combined low- and high-\qsq regions, preliminary studies suggest a statistical sensitivity to $A^{\Delta\Gamma}$ of $0.05$ can be achieved with a $300\invfb$ data set. 

With the \upgradetwo data set it will also be possible to perform a time-dependent angular analysis of the $\bquark \to \dquark$ process \decay{\Bd}{\rho^0\mumu}. 
This process differs from \decay{\Bs}{\phi\mumu} in two important regards: it is CKM suppressed and therefore has a smaller SM branching fraction; and $\Delta \Gamma_d \approx 0$, removing sensitivity to $A^{\Delta\Gamma}$. 
The uncertainties on the angular observables are expected to be on the order of $0.1$ for this case. 

The time-dependent angular analyses will still be statistically limited even with $300\invfb$. 
It will be important to maintain good decay-time resolution and the performance of the particle identification will be crucial to control backgrounds, as well as to improve flavour tagging performance. 

\subsubsection{Measurements of $b\to s\gamma$}

The time dependent \CP asymmetry of \decay{\B}{f_{\CP}\gamma} arises from the interference between decay amplitudes with and without $\Bds-\Bdsb$ mixing and is predicted to be small in the SM\ \cite{Atwood:1997zr,Ball:2006cva,Matsumori:2005ax}.
As a consequence, a large asymmetry due to interference between the \B mixing and decay diagrams can only be present if the two photon helicities contribute to both \B and \Bb decays.
From the time dependent decay rate
\begin{align}
    \Gamma(\decay{\Bds(\Bdsb)}{f_{\CP}\gamma})(t) \sim e^{-\Gamma_s t}
    &\big[
        \cosh\left(\frac{\Delta\Gamma_{(s)}}{2}\right)
        - \mathcal{A}^{\Delta}\sinh\left(\frac{\Delta\Gamma_{(s)}}{2}\right) \pm \nonumber\\
        & \pm \mathcal{C}_\CP\cos\left(\Delta m_{(s)} t\right)
        \mp \mathcal{S}_\CP\sin\left(\Delta m_{(s)} t\right)
    \big],
\end{align}
where $A^\Delta$, $\mathcal{C}_\CP$ and $\mathcal{S}_\CP$ depend on the photon polarisation~\cite{Muheim:2008vu}.
Two strategies can be devised:
one studying the decay rate independently of the flavour of the \B meson, which allows $A^\Delta$ to be accessed, and one tagging the flavour of the \B meson, which accesses $\mathcal{S}_\CP$ and $\mathcal{C}_\CP$.
The first strategy has been exploited at \lhcb to study the $4000$ \decay{\Bs}{\phi\gamma} candidates collected in Run 1 to obtain $A^\Delta=-0.98^{+0.46}_{-0.52}\stat ^{+0.23}_{-0.20}\syst$~\cite{LHCb-PAPER-2016-034}, compatible at two standard deviations from the prediction of $A^\Delta_{\text{SM}}=0.047^{+0.029}_{-0.025}$.

With $\sim60$k signal candidates expected with $50\,\invfb$, the full analysis, including flavour tagging information, will improve the statistical uncertainty on $A^\Delta$ to $\sim0.07$, and will need a careful control of the systematic 
uncertainties.
The analysis performed with $\sim800$k signal decays expected with $300\,\invfb$, with a statistical uncertainty to $\sim0.02$, requires some of the possible improvements in \piz reconstruction of the \upgradetwo detector 
to be able to use the full statistical power of the data.

In addition to studying the \Bs system, \lhcb can study the time-dependent decay rate of \decay{\Bz}{\KS\pip\pim\gamma} decays, which permits access of the photon polarisation through the $\mathcal{S}_\CP$ term.
With $\mathcal{O}(1000)$ signal events in Run 1, around $35$k and $200$k are expected at the end of \upgradeone and \upgradetwo, respectively
($1.75$k and $10$k when considering the flavour tagging efficiency), opening the doors to a very competitive measurement of $\mathcal{S}_\CP$ in the \Bz system.

Another way to study the photon polarisation is through the angular correlations among the three-body decay products of a kaonic resonance in \decay{\B}{K_{\mathrm{res}}(\to K\pi\pi)\gamma},
which allows the direct measurement of the photon polarisation parameter in the effective radiative weak Hamiltonian~\cite{Gronau:2002rz}. 
As a first step towards the photon polarisation measurement, \lhcb observed nonzero photon polarisation for the first time by studying the photon angular distribution in bins of $\Kp\pim\pip$ invariant mass\ \cite{LHCb-PAPER-2014-001}, but the determination of the value of this polarisation could not be performed due to the lack of knowledge of the hadronic system.
To overcome this problem, a method to measure the photon polarisation using a full amplitude analysis of \decay{\B}{K\pi\pi\gamma} decays is currently under development~\cite{Bellee:2018}, with an expected statistical sensitivity on the photon polarisation parameter of $\sim5\%$ in the charged mode with the Run 1 dataset.
The extrapolation of the precision to $300\,\invfb$  results in a statistical precision better than $1\%$, and hence control of the systematic uncertainties will be crucial.

The polarisation of the photon emitted in $b\to s\gamma$ transitions can also be accessed via semileptonic $b\to s\ell\ell$ transitions, for example in the decay $B^0\to\Kstarz\ell^+\ell^-$. Indeed, as mentioned in 
previous sections, at very low $q^2$ these decays are dominated by the electromagnetic dipole operator ${\cal O}_7^{(\prime)}$. Namely, the longitudinal polarisation fraction ($\FL$) is expected to be below $20\%$ for $q^2<0.2\gevgevcccc$.
In this $q^2$ region, the angle $\phi$ between the planes defined by the dilepton system and the $\Kstarz\to K^+\pi^-$ decay is sensitive to the $b\to s\gamma$ photon helicity.

While the $\Kstarz\mumu$ final state is experimentally easier to select and measure at LHCb, the $\Kstarz\epem$ final state allows $q^2$ values below $4m_\mu^2$ to be probed, 
where the sensitivity to the photon helicity is maximal.
Compared to the radiative channels used for polarisation measurements, the $B^0\to\Kstarz\epem$ final state is fully charged and gives better mass resolution and therefore better separation from partially reconstructed backgrounds.

The sensitivity of this decay channel at LHCb was demonstrated by an angular analysis performed with Run 1 data~\cite{LHCb-PAPER-2014-066}. The angular observables most sensitive to the photon polarisation at low $q^2$ are $A_{\rm T}^{(2)}$ and $A_{\rm T}^{\rm Im}$, as defined in Ref.~\cite{LHCb-PAPER-2014-066}. 
Indeed, in the limit $q^2\to 0$, these observables can be expressed by the following functions of $C_{7,7^{\prime}}$ (assuming NP contributions to be much smaller than $|C_7^{\rm SM}|$):
\begin{equation}
  \label{eq:qSqToZero} 
  A_{\rm T}^{(2)} (\qsq \to 0) \simeq 2 \frac{\Real (C_7^{' \ast}) } {| C_7 |}  \quad {\rm and} \quad  A_{\rm T}^{\rm Im} (\qsq \to 0) \simeq 2 \frac{\Imag (C_7^{' \ast}) } {| C_7 |}.
\end{equation}
In order to maximise the sensitivity to the photon polarisation, 
the angular analysis should be performed as close as possible 
to the low $q^2$ endpoint. However, the events at extremely low $q^2$ have worse $\phi$ resolution (because the two electrons are almost collinear) and are polluted by $B^0\to\Kstarz\gamma$ decays with the $\gamma$ converting in the VELO material. In the Run 1 analysis~\cite{LHCb-PAPER-2014-066} the minimum required $m(\epem)$ was set at 20\mevcc, but this should
be reduced as the \upgradetwo VELO detector will have a significantly lower material budget (multiple scattering is the main effect worsening the $\phi$ resolution). 
Similarly, the background from $\gamma$ conversions will be reduced with a lighter RF-foil or with the complete removal of it in \upgradetwo~\cite{LHCb-PII-EoI}.

Using the signal yield as given in Table~\ref{tab:penguin:LU_extrapolations} leads to the following statistical sensitivities to $A_{\rm T}^{(2)}$ and $A_{\rm T}^{\rm Im}$: 12\% with 8\invfb, 7\% with 23\invfb and 2\% with 300\invfb.
The theoretical uncertainty induced when this observable is translated into a photon polarisation measurement is currently at the level of $2\%$ but should improve by the time of the \upgradetwo analyses.
The current measurements performed with Run 1 data have a systematic uncertainty of order $5\%$ coming mainly from the modelling of the angular acceptance and from the uncertainty on the angular shape of the combinatorial background. The acceptance is independent of $\phi$ at low $q^2$ and its
modelling can be improved with larger simulation samples and using the proxy channel $\Bd\to\Kstarz\jpsi(\to\epem)$. 

Weak radiative decays of \bquark baryons are largely unexplored, with the best limits coming from CDF: $\mathcal{B}(\decay{\Lb}{\Lz\gamma}) < 1.3\times10^{-3}$ at $90\%\,$CL~\cite{Acosta:2002fh}.
They offer a unique sensitivity to the photon polarisation through the study of their angular distributions, and will constitute one of the main topics in the radiative decays programme in the \lhcb \upgradetwo.

With predicted branching fractions of $O(10^{-5}-10^{-6})$, the first challenge for \lhcb will be their observation, as the production of long-lived particles in their decay, in addition to the photon, means in most cases that the $b$-baryon secondary vertex cannot be reconstructed. This makes their separation from background considerably more difficult than in the case of regular radiative \bquark decays.

The most abundant of these decays is \decay{\Lb}{\Lz(\to p\pim)\gamma}, which is sensitive to the photon polarisation mainly\footnote{In the following, we assume that the \Lb (and any other beauty baryon) polarisation is zero~\cite{LHCb-PAPER-2012-057}, removing part of the photon polarisation dependence.} through the distribution of the angle between the proton and the \Lz momentum in the rest frame of the \Lz ($\theta_p$), 
\begin{equation}
    \frac{\operatorname{d}\Gamma}{\operatorname{d}\cos\theta_p} \propto 1 - \alpha_\gamma \alpha_{p,1/2}\cos\theta_p, 
\end{equation}
where $\alpha_\gamma$ is the asymmetry between left- and right-handed amplitudes and $\alpha_{p,1/2}=0.642\pm0.013$~\cite{PDG2018} is the \decay{\Lz}{p\pim} decay parameter.
Using specialised trigger lines for this mode $15-150$ signal events are expected using the Run 2 dataset. Preliminary studies show that a statistical sensitivity to $\alpha_\gamma$ of $(20-25)\%$ is expected with these data, which would be reduced to $\sim15\%$ with $23\,\invfb$ and below $4\%$ with $300\,\invfb$.
In the \lhcb \upgradetwo, the addition of timing information in the calorimeter will be important to be able to study this combinatorial-background dominated decay;
additionally, improved downstream reconstruction would allow the use of downstream \Lz decays, which make up more than $2/3$ of the total signal.

The \decay{\Xib}{\Xi^-(\to\Lz(\to p\pim)\pim)\gamma} decay presents a richer angular distribution, with dependence to the photon polarisation in both the \Lz angle ($\theta_\Lz$) and proton angle ($\theta_p$),
\begin{equation}
    \frac{\operatorname{d}\Gamma}{\operatorname{d}\cos\theta_\Lz\cos\theta_p} \propto 1 - \alpha_\gamma \alpha_\Xi \cos\theta_\Lz + \alpha_{p,1/2}\cos\theta_p\left(\alpha_\Xi-\alpha_\gamma\cos\theta_\Lz\right),
\end{equation}
but the lower $\sigma(\decay{pp}{\Xib})$, combined with a lower reconstruction efficiency due to the presence of one extra track, results in an order of magnitude fewer events than in the \Lb case, making the increase of 
statistics from the \upgradetwo even more relevant. With a similar sensitivity to the photon polarisation to that of \decay{\Lb}{\Lz(\to p\pim)\gamma}, \decay{\Xib}{\Xi^-\gamma} decays will allow this parameter to be probed with a precision of $40\%$ and $10\%$ with $23$ and $300\,\invfb$, respectively.

\subsubsection{Measurements of $b\to cl\nu$ including $B_c$ and $b$-baryon prospects}

\begin{figure}[!tb]
\centering
\includegraphics[width=0.7\linewidth]{section7/figures/RX_projection_stat_syst.pdf}
\caption{
The projected absolute uncertainties on $\mathcal{R}(D^{\ast}$ and $\mathcal{R}(J/\psi)$ (see Sect.~\ref{subsec:OtherBhadronRX}) from the current sensitivities (at 3\invfb) to 23\invfb, 50\invfb, and 300\invfb.
}
\label{fig:RXproj}
\end{figure} 

LHCb has made measurements of \RDb using both muonic ($\tau^{+} \to \mup \nu \nu$) and hadronic ($\tau^{+} \to \pip \pim \pip \nu$) decays of the tau lepton~\cite{LHCb-PAPER-2015-025,LHCb-PAPER-2017-017,LHCb-PAPER-2017-027}.
Due to the presence of multiple neutrinos these decays are extremely challenging to measure.
The measurements rely on isolation techniques to suppress partially reconstructed backgrounds, 
\B meson flight information to constrain the kinematics of the unreconstructed neutrinos, and a multidimensional template fit to determine the signal yield. 
Figure~\ref{fig:RXproj} shows how the absolute uncertainties on the LHCb muonic and hadronic $\mathcal{R}(D^{\ast})$ measurements are projected to evolve with respect to the current status.
The major uncertainties are the statistical uncertainty from the fit, the uncertainties on the background modelling and the limited size of simulated samples.
A major effort is already underway to commission fast simulation tools.
The background modelling is driven by a strategy of dedicated control samples in the data, and so this uncertainty will continue to improve with larger data samples.
From Run 3 onward it is assumed that, taking advantage of the full software HLT, the hadronic analysis can normalise directly to the $B^0 \to D^{\ast -}\mu^+\nu_{\mu}$  decay,
thus eliminating the uncertainty from external measurements of $\mathcal{BR}(B^0 \to D^{\ast -} \pi^+\pi^-\pi^+)$.
It is assumed that all other sources of systematic uncertainty will scale as $\sqrt{\mathcal{L}}$.
With these assumptions, an absolute uncertainty on $\mathcal{R}(D^{\ast}$ of $0.003$ will be achievable for the muonic and hadronic modes with the 300\invfb Upgrade II dataset.

On the timescale of \upgradetwo, interest will shift toward new observables  beyond the branching fraction ratio~\cite{Becirevic:2016hea}.
The kinematics of the \dsttaunu decays is fully described by the dilepton mass, and three angles which are denoted $\chi$, $\theta_L$ and $\theta_D$. 
LHCb is capable of resolving these three angles, as can be seen in~\figref{fig:RDAngles}.
However, the broad resolutions demand very large samples to extract the underlying physics. The decay distributions within this kinematic space are governed by the underlying spin structure, and precise measurements of these distributions will allow the different helicity amplitudes to be disentangled.
This can be used both to constrain the spin structure of any potential new physics contribution, and to measure the hadronic parameters
governing the \dsttaunu decay, serving as an essential baseline for SM and non-SM studies.
The helicity-suppressed amplitude which presently dominates the theoretical uncertainty on \RDb is too strongly suppressed in the 
\dbmunu decays to be measurable, however this can be accessed in the \dbtaunu decay directly.
If any potential new physics contributions are assumed not to contribute via the helicity-suppressed amplitude then the combined measurements of \dbmunu and \dbtaunu decays will allow for a fully data-driven prediction for
\RDb under the assumption of lepton universality, eliminating the need for any theory input relating to hadronic form factors.
However, these measurements have yet to be demonstrated with existing data.
This exciting programme of differential measurements needs to be developed on Run~1 and 2 data before any statement is made about the precise sensitivity, 
but it offers unparalleled potential to fully characterise both the SM and non-SM contributions to the $b \to c \tau \nu$ transition.

\begin{figure}[!tb]
\centering
\includegraphics[width=0.45\linewidth]{section7/figures/thetaD.pdf}
\includegraphics[width=0.45\linewidth]{section7/figures/thetaL.pdf}
\includegraphics[width=0.45\linewidth]{section7/figures/thetaC.pdf}
\caption{
Angular resolution for simulated \dstmunu (black) and \dsttaunu  (red) decays, with $\tau^{+} \to \mup \nu \nu$. 
This demonstrates our ability to resolve the full angular distribution, with some level of statistical dilution.
}
\label{fig:RDAngles}
\end{figure} 

As measurements in \RDst become more statistically precise, it will become increasingly more 
urgent to provide supplementary measurements in other \bquark-hadron species with different background 
structure and different sources of systematic uncertainties. For example, the \decay{\Bsb}{\Dsp \taum\neub} and \decay{\Bsb}{\Dssp\taum\neub} decays
will allow supplementary 
measurements at high yields, and do not suffer as badly from cross-feed backgrounds from other 
mesons, unlike, for example, \decay{\Bzb }{ \Dstarp \taum\neub}, where the \Bp and \Bs both contribute to 
the $\Dstarp \mu X$ or $\Dstarp \threepim X$ final states. 
Furthermore, the comparison of decays with different spins of the $b$ and $c$ hadrons can enhance our sensitivity 
to different NP scenarios~\cite{Azatov:2018knx,LHCb-PAPER-2017-016}.
No published measurements exist for the $\Bs$ case yet, but based on known relative efficiencies and assuming 
the statistical power of this mode tracks \RDorDst, we expect less than $6\%$ relative uncertainty 
after Run~3, and $2.5\%$ with the \upgradetwo data, where limiting systematic uncertainties 
are currently expected to arise from corrections to 
simulated pointing and vertex resolutions, from knowledge of particle identification efficiencies, 
and from knowledge of the backgrounds from random combinations of charm and muons. It is conceivable 
that new techniques and control samples could further increase the precision of these measurements. 

Methods 
are currently under development for separating the \decay{\Bsb}{\Dssp\ell^{-}\neub} and \decay{\Bsb}{\Dsp\ell^{-}\neub} modes, and given the
relative slow pion (\decay{\Dstarp }{ \Dz\pip}) and soft photon (\decay{\Dssp }{ \Dsp\gamma}) efficiencies, the precision in \decay{\Bsb}{ \Dsp \tau \nu} decays can be expected to exceed that in
\decay{\Bsb }{ \Dssp \tau \nu}, the reverse of the situation for $\RDorDst$.
An upgraded ECAL would extend the breadth and sensitivity of $\mathcal{R}(D^{*(*)+}_{s})$ measurements possible
in the \upgradetwo\ scenario above and beyond the possible benefits of improved neutral isolation in 
$\RD$ or $\mathcal{R}(\Dsp)$ measurements.

Of particular interest are the semitauonic decays of
\bquark baryons and of \Bcp mesons.
The former provides probes of entirely new Lorentz structures of NP operators
which pseudoscalar to pseudoscalar or vector transitions simply do not access.
The value of probing this supplementary space of couplings has already been demonstrated by
LHCb with its Run~1
measurement of $|\Vub|$ via the decay \decay{\Lb}{\proton\mun\neub}, which places strong constraints on 
right-handed currents sometimes invoked to explain the inclusive-exclusive tensions in that quantity. By the end of Run~3, it is expected that the relative uncertainty for $\mathcal{R}(\Lc)$ will reach below $4\%$, and $2.5\%$ by the end of \upgradetwo. 
A further exciting prospect is the study of $b \to u\mu \nu$ decays, which have been beyond experimental reach thus far.
For example the decay $B^+ \to p\bar{p}\mu\nu$ offers a clean experimental signature. 
Our capabilities with this decay could benefit from the enhanced low momentum proton identification with the TORCH subdetector.

Meanwhile, the \decay{\Bcp }{ \jpsi \taum \neub} decay
is an entirely unique state among the flavoured mesons as the bound state of two distinct 
flavors of heavy quark, and, through its abundant decays to charmonium final states, provides a 
highly efficient signature for triggering and reconstruction at high instantaneous luminosities. 
Measurements of \decay{\Bcp }{ \jpsi \ell \neub} decays involve a trade-off between the approximately 100 times 
smaller production cross-section for \Bcp verses the extremely efficient \decay{\jpsi}{\mup\mun} signature in the LHCb 
trigger. For illustration, in Run~1, LHCb reconstructed 
and selected 19\,000 \decay{\Bcp }{ \jpsi \mun \neub} decays, compared with 360\,000 \decay{\Bzb}{\Dstarp\mun\neub}. This resulted in a measurement of $\mathcal{R}(\jpsi)=0.71\pm 0.17\pm 0.18$ \cite{LHCb-PAPER-2017-035}. As a result of the smaller production cross-section, the muonic measurements have large backgrounds from \decay{h}{ \mu} misidentification from the relatively abundant \decay{\B }{ \jpsi X_h} decays, where $X_h$ is any collection of hadrons, and so they
are very sensitive to the performance of the muon system and PID algorithms in the future. Here it is assumed that 
it will be possible to achieve similar performance to Run 1 in the upgraded system. 

To project the sensitivity for \decay{\Bcp }{ \jpsi \taum \neub} based on Ref.~\cite{LHCb-PAPER-2017-035}, it is assumed that 
all the systematic uncertainties can be reduced with the size of the input data except for those that were assumed not to
scale with data for the previous predictions. For these, we assume that they can be reduced up until they reach 
the same absolute size as the corresponding systematic uncertainties in the Run~1 muonic $\RDst$ analysis. In addition, it is
assumed that sometime in the 2020s lattice QCD calculations of the form factors for this process will allow 
the systematic uncertainty due to signal form factors to be reduced by an additional factor of two. This results in
a projected absolute uncertainty for the muonic mode of $0.07$ at the end of Run~3 
and $0.02$ by the end of \upgradetwo,  as can be seen in Fig.~\ref{fig:RXproj}.
Measurements in the hadronic mode can be expected to reach similar sensitivities.

\subsubsection{Searches for LFV, LNV, BNV and interplay with tests of LU}

The LHCb collaboration has recently published~\cite{LHCb-PAPER-2017-031} the world's best limits on the branching fractions of the \BsToEMu
and \BdToEMu decays using the first 3\invfb collected in 2011 and 2012 at 7 and 8\tev respectively. The acceptance of the \BsToEMu decays can be affected by the relative contribution of the two \Bs mass eigenstates to the total decay amplitude, due to their large lifetime difference. Therefore, the upper limit on the branching fraction of \BsToEMu decays is evaluated in two extreme hypotheses: where the amplitude is completely dominated by the heavy eigenstate or by the light eigenstate. The results are  $\BF(\BsToEMu) < 6.3\,(5.4) \times 10^{-9}$ and $\BF(\BsToEMu) < 7.2\,(6.0) \times 10^{-9}$ at $95\%\,(90\%)$ CL, respectively. The limit for the branching fraction of the \Bd mode is  $\BF(\BdToEMu) < 1.3\,(1.0) \times 10^{-9}$ at $95\%\,(90\%)$ CL.

Assuming similar performances in background rejection and signal retention as in the current analysis, at the end of the \upgradeone data taking period the LHCb
experiment will be able to probe branching fractions of \BsToEMu and \BdToEMu decays down to $8\times 10^{-10}$
and $2\times 10^{-10}$, respectively. The additional statistics accumulated during the \upgradetwo data taking period will push down
these limits to $3\times 10^{-10}$ and $9\times 10^{-11}$ respectively, close to the interesting region where NP effects may appear. The improvement at \upgradetwo\ over
\upgradeone\ in electron  reconstruction will be very important in attaining, or exceeding, this goal. 

An upper limit on the \BdToTauMu channel has been already set by $\babar$: $\BR\left( \BdToTauMu\right)< 2.2\times 10^{-5} $ at $90\%$~CL~\cite{Aubert:2008cu}. The first search on the \BsToTauMu channel is in progress in LHCb and the results are expected soon on data recorded in 2011 and 2012 using the \tauppp and \tauppppi0 decay modes.
Given the presence of a neutrino that escapes detection this kind of analysis is much more complicated than those investigating electron or muon final states. A specific reconstruction technique is used in order to infer the energy of the $\nu$, taking advantage of the known $\tau$ vertex position given by the $3\pi$ reconstructed vertex. 
This way, the complete kinematics of the process can be solved up to a two-fold ambiguity. LHCb expects to reach sensitivities of a few times $10^{-5}$ with the Run~1 and 2 data sets. Extrapolating the current measurements to the \upgradetwo LHCb could reach  $\BR\left( \BdToTauMu\right)< 3\times 10^{-6} $ at $90\%$~CL. The mass reconstruction technique depends heavily on the uncertainty on the primary and the $\tau$ decay vertices, hence improvement in the tracking system in \upgradetwo, including a removal or reduction in material of the VELO RF foil, will be very valuable.

If New Physics allows for charged lepton flavour violation then the branching fractions of $B\to K \ell \ell^{'}$  or $\Lb \to \Lz \ell \ell^{'}$ will be enhanced with respect to their purely leptonic counterparts, since the helicity suppression is lower. 
Furthermore, if observed, they would allow the measurement of more observables with respect to the lepton flavour violating decays discussed in the previous sections, thanks to their multi-body final states and, in the case of $\Lb$, to the non-zero initial spin. 

In many generic new physics models with lepton flavour universality violation, charged lepton flavour violating decays of $b$-hadrons can be linked with the anomalies recently measured in $b\rightarrow s\ell\ell$ decays~\cite{LHCb-PAPER-2014-024,LHCb-PAPER-2017-013,LHCb-PAPER-2015-051}. 
The current  limits set by the \bfactories on the branching fractions of $B \to Ke \mu$ and $B \to K\tau \mu$ decays are $< 13\times 10^{-8}$~\cite{Aubert:2006vb} and $< 4.8\cdot 10^{-5}$~\cite{Lees:2012zz}  at 90\% confidence level, respectively.  

At LHCb, searches for $\decay{\Bu}{\Kp e^\pm\mu^\mp}$, $\decay{\Bd}{\Kstarz\tau^\pm\mu^\mp}$, $\decay{\Bu}{\Kp\tau^\pm\mu^\mp}$ and $\decay{\Lb}{\Lz e^\pm\mu^\mp}$ are ongoing. These searches are complementary, as charged lepton flavour violation couplings among different families are expected to be different.
The analyses involving $\tau$ leptons reconstruct candidates via the $\decay{\taum}{\pim\pim\pip\nu_{\tau}}$ channel,
which allows the reconstruction of the $\tau$ decay vertex.\footnote{It should be noted that searches for $\decay{\Bu}{\Kp\tau^\pm\mu^\mp}$ from $B_{s2}^*$ without $\tau$ reconstruction can give complementary information.} 
All these decays contain at least one muon, which is used to efficiently trigger on the event. Usually, since these decays involve combinations of leptons that are not allowed in the Standard Model, the backgrounds can be kept well under control,  leaving very clean samples only polluted by candidates formed by the random combinations of tracks. This combinatorial effect is higher for the channel with a $\tau$ in the final state decaying into three charged pions.  The other relevant background  comes from chains of semileptonic decays, where two or more neutrinos are emitted and therefore combinations of leptons of different flavours are possible. These decays have typically a low reconstructed invariant mass, due to the energy carried away by the neutrinos, and so they do not significantly pollute the signal region. 

The expected upper limits at LHCb using the first $9 \invfb$ of data taken are
$\mathcal{O}(10^{-9})$ and $\mathcal{O}(10^{-6})$ for the $\decay{\Bu}{\Kp e^\pm\mu^\mp}$ and $\decay{\Bd}{\Kstarz\tau^\pm\mu^\mp}$ decays respectively, at 90\% confidence level.
The limit for $\decay{\Bu}{\Kp\tau^\pm\mu^\mp}$ is expected to be similar to $\decay{\Bd}{\Kstarz\tau^\pm\mu^\mp}$.
The sensitivity of these analyses scales almost linearly with luminosity  for $\decay{\Bu}{\Kp e^\pm\mu^\mp}$, 
and with the square root of the luminosity for $\decay{\Bd}{\Kstarz\tau^\pm\mu^\mp}$.
In both cases, the expected limits using the \upgradetwo data are in the region of interest of the models currently developed for explaining the $B$ anomalies, so they will provide strong constraints on the New Physics scenarios with charged lepton flavour violation. 

Experimentally, LNV and BNV measurements are null searches, so sensitivity is assumed
to scale linearly with luminosity $L$ when the background
is negligible and as $\sqrt L$ if the background is significant. LHCb has already published searches in certain channels, and others are
in progress:
\begin{itemize}
  \item Searches for LNV in various $B$-meson decays of the form
    $B \to X \mu^+ \mu^+$, where $X$ is a system of one or more hadrons.
    The principal motivation is the sensitivity to contributions from Majorana neutrinos~\cite{Atre:2009rg},
    which may be on-shell or off-shell, depending on the decay mode.
    The published results consist of
      searches for $\decay{\Bp}{\Km \mu^+ \mu^+}$, $\decay{\Bp}{\pim \mu^+ \mu^+}$ and $\decay{\Bu}{D^+_{(s)}\mun\mun}$~\cite{LHCb-PAPER-2011-009, LHCb-PAPER-2011-038, LHCb-PAPER-2013-064}. A limit of $\mathcal{B}(B^+ \to \pi^- \mu^+ \mu^+) < 4 \times 10^{-9}$ is set at the 95\% confidence level, along with more detailed limits as a function of the Majorana neutrino mass. Since the combinatorial background was found to be low but not negligible with the Run~1 data, we estimate that the limit can be improved by a factor of ten with the full \upgradetwo dataset.
  \item Search for BNV in \Xibz oscillations~\cite{LHCb-PAPER-2017-023}.
    Six-fermion, flavour-diagonal operators, involving two fermions from each
    generation, could give rise to BNV/LNV without violating the nucleon stability
    limit~\cite{Smith:2011rp,Durieux:2012gj}.
    Since the \Xibz~($bsd$) has one valence quark from each generation, it could
    couple directly to such an operator and oscillate to \Xibzbar.
    The published search used the Run1 data and set a lower limit on the oscillation
    period of 80\ps. Since events are tagged by decays of
    the \XibPrimeMinus and \XibStarMinus resonances, with the former being particularly
    clean, and since the analysis also uses the decay-time distribution of events,
    the sensitivity is expected to scale linearly. 
    Although the decay mode used in the published analysis is hadronic
    ($\Xibz \to \Xicp \pim$), future work could also benefit from the
    lower-purity but higher-yield semileptonic mode $\Xibz \to \Xicp \mun \neumb$.
  \item $\Lc \to \antiproton \mu^+ \mu^+$.
    This channel has previously been investigated at the $e^+ e^-$ \bfactories.
    The current upper limit, obtained by \babar~\cite{Lees:2011hb}, is
    $\mathcal{B}(\Lc \to \antiproton \mup \mup) < 9.4 \times 10^{-6}$
    at the 90\% confidence level.
    With Run~1 and~2 data alone, it should be possible to reduce this
    to $1 \times 10^{-6}$. Further progress depends on the background
    level, but an additional factor of 5--10 with the full \upgradetwo statistics
    is likely.
  \item $\Lc \to \mu^+ \mu^- \mu^+$.
    Experimentally, this is a particularly promising decay mode:
    the final state with three muons is very clean, and there are
    no known sources of peaking background.
    This search could be added for little extra effort to the
    $\taum \to \mup \mun \mun$ search described in the
    preceding section.
\end{itemize}
